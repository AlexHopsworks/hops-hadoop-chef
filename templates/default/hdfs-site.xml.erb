<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<!-- Put site-specific property overrides in this file. -->

<configuration>
<!-- 
<property>
  <name>dfs.replication</name>
  <value><%= node[:hadoop][:repl] %></value>
  <description>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
  </description>
</property>

<property>
<name>dfs.namenode.http.address</name>
<value><%= @addr1 %></value>
  <description> default port is 50070 but had to change it because it already in use
  </description>
</property>

<property>
<name>dfs.datanode.address</name>
<value><%= @addr2 %></value>
  <description> default port is 50070 but had to change it because it already in use
  </description>
</property>

<property>
<name>dfs.datanode.http.address</name>
<value><%= @addr3 %></value>
  <description> default port is 50070 but had to change it because it already in use
  </description>
</property>

<property>
<name>dfs.datanode.ipc.address</name>
<value><%= @addr4 %></value>
  <description> default port is 50070 but had to change it because it already in use
  </description>
</property>

<property>
<name>dfs.datanode.https.address</name>
<value><%= @addr5 %></value>
  <description> default port is 50070 but had to change it because it already in use
  </description>
</property>

<property>
  <name>dfs.namenode.rpc-address</name>
  <value>10.0.2.15:13001</value>
  <description>
    RPC address that handles all clients requests. In the case of HA/Federation where multiple namenodes exist,
    the name service id is added to the name e.g. dfs.namenode.rpc-address.ns1
    dfs.namenode.rpc-address.EXAMPLENAMESERVICE
    The value of this property will take the form of hdfs://nn-host1:rpc-port.
  </description>
</property>

-->


<property>
  <name>dfs.leader.check.interval</name>
  <value><%= node[:hadoop][:leader_check_interval_ms] %></value>
</property>

<property>
  <name>dfs.leader.missed.hb</name>
  <value><%= node[:hadoop][:missed_hb] %></value>
</property>

<property>
  <name>dfs.client.max.retires.on.failure</name>
  <value>1</value>
</property>

<property>
  <name>dsf.client.refresh.namenode.list</name>
  <value>60000</value>
</property>

<property>
  <name>dfs.client.block.write.locateFollowingBlock.retries</name>
  <value>10</value>
</property>

<property>
  <name>dfs.webhdfs.enabled</name>
  <value>true</value>
</property>


<!-- Do not modify this file directly.  Instead, copy entries that you -->
<!-- wish to modify from this file into hdfs-site.xml and change them -->
<!-- there.  If hdfs-site.xml does not already exist, create it.      -->

<property>
  <name>hadoop.hdfs.configuration.version</name>
  <value>1</value>
  <description>version of this configuration file</description>
</property>

<property>
  <name>dfs.blocksize</name>
  <value>256m</value>
  <description>
      The default block size for new files, in bytes.
      You can use the following suffix (case insensitive):
      k(kilo), m(mega), g(giga), t(tera), p(peta), e(exa) to specify the size (such as 128k, 512m, 1g, etc.),
      Or provide complete size in bytes (such as 134217728 for 128 MB).
  </description>
</property>


<property>
  <name>dfs.namenode.accesstime.precision</name>
  <value>3600000</value>
  <description>The access time for HDFS file is precise upto this value. 
               The default value is 1 hour. Setting a value of 0 disables
               access times for HDFS.
  </description>
</property>


<property>
   <name>dfs.namenode.handler.count</name>
  <value>200</value>
  <description>The RPC server that listens to requests from clients</description>
</property>

<!--property>
   <name>dfs.namenode.service.handler.count</name>
  <value>10</value>
  <description>The RPC server threads that listens to requests from DataNodes</description>
</property-->

<property>
   <name>dfs.storage.ansestor.lock.type</name>
  <value>READ_COMMITTED</value>
  <description>Lock type for ancestors in the file path. Values: READ | READ_COMMITTED</description>
</property>


<property>
   <name>dfs.namenode.inodeid.batchsize</name>
  <value>100000</value>
  <description></description>
</property>

<property>
   <name>dfs.namenode.blockid.batchsize</name>
  <value>100000</value>
  <description></description>
</property>


<property>
   <name>dsf.client.refresh.namenode.list</name>
  <value>60000</value>
  <description>Time in ms</description>
</property>

<property>
   <name>dfs.namenode.selector-policy</name>
  <value>ROUND_ROBIN</value>
  <description>Used by clients. Possible values ROUND_ROBIN, RANDOM</description>
</property>

<property>
  <name>dfs.namenode.safemode.extension</name>
  <value>30000</value>
  <description>
    Determines extension of safe mode in milliseconds
    after the threshold level is reached.
  </description>
</property>

<property>
  <name>dfs.namenode.processReport.batchsize</name>
  <value>10000</value>
  <description>
    
  </description>
</property>

<property>
  <name>dfs.namenode.misreplicated.batchsize</name>
  <value>500</value>
  <description>
    
  </description>
</property>

<property>
  <name>dfs.namenode.misreplicated.noofbatches</name>
  <value>10</value>
  <description>
  </description>
</property>

<property>
  <name>dfs.namenode.legacy-rename.enable</name>
  <value>false</value>
  <description>
  </description>
</property>

<property>
  <name>dfs.storage.driver.configfile</name>
  <value>ndb.config</value>
  <description>
  </description>
</property>

<property>
  <name>dfs.namenode.logging.level</name>
  <value><%= node[:hops][:log_level] %></value>
  <description>
    The logging level for dfs namenode. Other values are "dir" (trace
    namespace mutations), "block" (trace block under/over replications
    and block creations/deletions), or "all".
  </description>
</property>

</configuration>
